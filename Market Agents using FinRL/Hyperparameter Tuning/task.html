<div class="step-text">
<h5 id="description">Description</h5>
<p></p><div class="alert alert-warning">We recommend you to implement this stage in Google Colab. Before completing this stage, we recommend you to enable GPU in your notebook in Google Colab.</div>
<p>In the final stage, you will optimize the model by tuning hyperparameters using Optuna. This stage involves defining the objective function for optimization and using Optuna to find the best hyperparameters, thereby improving the model's performance. Hyperparameter tuning is a critical step in enhancing the model's accuracy and robustness.</p>
<p>In this stage, you will:</p>
<ol>
<li>Define the objective function for optimization, specifying the parameters to tune.</li>
<li>Use Optuna to perform a search for the optimal hyperparameters.</li>
<li>Train the model using the optimized parameters and validate its performance.</li>
<li>Save the best hyperparameters and the trained model for future use.</li>
</ol>
<p>By the end of this stage, you will have an optimized model with improved performance, ready for deployment or further analysis.</p>
<p>You can use this <a href="https://cogniterra.org/media/attachments/lesson/39679/markets_agents_stage4.ipynb" rel="noopener noreferrer nofollow" target="_blank">Colab template</a> (recommended) or copy-paste the code below, to complete this stage:</p>
<pre><code class="language-python">EPISODES = # number of episodes to train the model

# Define the objective function
def objective(trial):
    lr = # use trial to suggest values for lr
    k_size = # use trial to suggest values for k_size
    time_window = # use trial to suggest values for time_window

    # set up train environment
    enviroment_test = PortfolioOptimizationEnv(
    ) # complete the code

    # setup model kwargs
    model_kwargs = {
        "lr": lr,
        "policy": EIIE,
    }
    # setup policy kwargs
    policy_kwargs = {
        "k_size": k_size,
        "time_window": time_window,
    }
    # Train model using DRLAgent
    model = DRLAgent(environment_train).get_model("pg", device, model_kwargs, policy_kwargs)
    DRLAgent.train_model(model, episodes=10)

    # define test environment
    enviroment_test = PortfolioOptimizationEnv(
    ) # complete the code

    # validate with test environment
    DRLAgent.DRL_validation(...) # complete the code

    # final portfolio value as metric for the optimization
    return environment_test._asset_memory["final"][-1]


# Create a study and optimize the objective function
study = optuna.create_study(direction='maximize')
N_TRIALS = # select the number of trails for the optimization
study.optimize(objective, n_trials=N_TRIALS)
</code></pre>
<p>At the end of the stage get print the best hyperparameters values: </p>
<pre><code class="language-python"># print the best hyperparameters
BEST_HYPERPARAMETERS = # using the study get the best hyperparameters
print("Best hyperparameters: ", BEST_HYPERPARAMETERS)</code></pre>
<h5 id="objectives">Objectives</h5>
<p>To complete this stage:</p>
<ol>
<li>Define the objective function for optimization.</li>
<li>Use Optuna to find the best hyperparameters.</li>
<li>Train and validate the model with the optimized parameters.</li>
</ol>
<h5 id="examples">Examples</h5>
<p><strong>Example 1:</strong><em> an example of the program output</em></p>
<pre><code class="language-no-highlight">Best hyperparameters:  {'lr': 0.024951148793730334, 'k_size': 2, 'time_window': 28}</code></pre>
</div>